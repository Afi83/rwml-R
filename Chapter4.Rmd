---
title: "Real-World Machine Learning (with R): Chapter 4"
author: "Paul Adamson"
date: "October 23, 2016"
output: html_document
---

This notebook contains R code to accompany Chapter 4 of the book 
["Real-World Machine Learning"](https://www.manning.com/books/real-world-machine-learning),
by  Henrik Brink, Joseph W. Richards, and Mark Fetherolf.  It is part of a 
series of R Markdown notebooks hosted on GitHub in the 
[rwml-R repo](https://github.com/padamson/rwml-R).

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/analytics/real-world-machine-learning-R/")
library(plyr)
library(dplyr)
library(AppliedPredictiveModeling)
library(caret)
library(kknn)
library(RColorBrewer)
library(cowplot)
library(reshape2)
library(ROCR)
library(kernlab)
library(doMC)
set.seed(1234)
.pardefault <- par()
```

## Figure 4.9 The first five rows of the Titanic Passengers dataset 

As in Chapter 3, we are going to be interested in predicting survival, so again,
it is useful to specify 
the `Survived` variable to be of type `factor`. For visualizing the data, 
it is also useful to use the `revalue` function to specify the `no` and `yes`
levels for the `factor` variable. The `kable` function is built into the `knitr`
package.

```{r figure4.9, cache=TRUE}
titanic <- read.csv("data/titanic.csv", 
                    colClasses = c(
                      Survived = "factor",
                      Name = "character",
                      Ticket = "character",
                      Cabin = "character"))
titanic$Survived <- revalue(titanic$Survived, c("0"="no", "1"="yes"))
kable(head(titanic, 5), digits=2)
```

## Figure 4.10 Splitting the full dataset into training and testing sets

Here, we follow the same process used for Figure 3.6 to process the data and
prepare it for our model. First, we get rid of the variables that we do not 
want in our model.
(`Cabin` might actually be useful, but it's not used here.)
Then we use `is.na` to set missing age values to -1.
The `mutate` and `select` functions make it easy to take square root of 
the `Fare` variable and then drop it from the dataset.
We then drop rows with missing `Embarked` data and remove the unused level 
`""`. 
Finally, we convert `factor` variables to dummy variables using the 
`dummyVars` function in the `caret` package.
To avoid perfect collinearity (a.k.a. the dummy variable trap), we set
the `fullRank` parameter to `TRUE`.  `Survived.yes` is then converted back
to a `factor` variable, and its levels are changed back to 'yes' and 'no' again
(otherwise the `train` function in `caret` will complain later about
invalid R variable names).

We then make a 80/20% train/test split 
using the `Survived` factor
variable in the `createDataPartition` function to preserve the
overall class distribution of the data.

```{r figure4.10, cache=TRUE, dependson="figure4.9"}
titanicTidy <- subset(titanic, select = -c(PassengerId, Name, Ticket, Cabin))

titanicTidy$Age[is.na(titanicTidy$Age)] <- -1

titanicTidy <- titanicTidy %>%
  mutate(sqrtFare = sqrt(Fare)) %>%
  select(-Fare)

titanicTidy <- titanicTidy %>%
  filter(!(Embarked=="")) %>%
  droplevels

dummies <- dummyVars(" ~ .", data = titanicTidy, fullRank = TRUE)
titanicTidyNumeric <- data.frame(predict(dummies, newdata = titanicTidy))

titanicTidyNumeric$Survived.yes <- factor(titanicTidyNumeric$Survived.yes)
titanicTidyNumeric$Survived.yes <- 
  revalue(titanicTidyNumeric$Survived.yes, c("0"="no", "1"="yes"))

trainIndex <- createDataPartition(titanicTidyNumeric$Survived.yes, p = .8, 
                                  list = FALSE, 
                                  times = 1)

titanicTrain <- titanicTidyNumeric[ trainIndex,]
titanicTest  <- titanicTidyNumeric[-trainIndex,]

kable(head(titanicTidyNumeric, 8), digits=2)
kable(head(titanicTrain, 5), digits=2)
kable(head(titanicTest, 3), digits=2)
```

## Figure 4.18 Handwritten digits in the MNIST dataset 

Thanks to [Longhow Lam](https://longhowlam.wordpress.com/2015/11/25/a-little-h2o-deeplearning-experiment-on-the-mnist-data-set/)
for posting the code used in the `displayMnistSamples` function that display's 
digits from the MNIST dataset.

```{r figure4.18, cache=TRUE,fig.height=5}
mnist <- read.csv("data/mnist_small.csv",
                  colClasses = c(label = "factor"))
displayMnistSamples <- function(x) {
  for(i in x){
  y = as.matrix(mnist[i, 2:785])
  dim(y) = c(28, 28)
  image( y[,nrow(y):1], axes = FALSE, col = gray(0:255 / 255))
  text( 0.2, 0, mnist[i,1], cex = 3, col = 2, pos = c(3,4))
  }
}
par( mfrow = c(4,5), mai = c(0,0,0.1,0.1))
displayMnistSamples(sample(1:length(mnist),20))
```

## Figure 4.19 The confusion matrix for the 10-class MNIST handwritten digit classification problem

```{r figure4.19, cache=TRUE, dependson="figure4.18", fig.height=4}
trainIndex <- createDataPartition(mnist$label, p = .8, 
                                  list = FALSE, 
                                  times = 1)
mnistTrain <- mnist[ trainIndex,]
mnistTest  <- mnist[-trainIndex,]

mnist.kknn <- kknn(label~., mnistTrain, mnistTest, distance = 1,
                   kernel = "triangular")

confusionDF <- data.frame(confusionMatrix(fitted(mnist.kknn),mnistTest$label)$table)
confusionDF$Reference = with(confusionDF, 
                             factor(Reference, levels = rev(levels(Reference))))

jBuPuFun <- colorRampPalette(brewer.pal(n = 9, "BuPu"))
paletteSize <- 256
jBuPuPalette <- jBuPuFun(paletteSize)

confusionPlot <- ggplot(
  confusionDF, aes(x = Prediction, y = Reference, fill = Freq)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  geom_tile() +
  labs(x = "Predicted digit", y = "Actual digit") +
  scale_fill_gradient2(
    low = jBuPuPalette[1],
    mid = jBuPuPalette[paletteSize/2],
    high = jBuPuPalette[paletteSize],
    midpoint = (max(confusionDF$Freq) + min(confusionDF$Freq)) / 2,
    name = "") +
  theme(legend.key.height = unit(2, "cm"))

ggdraw(switch_axis_position(confusionPlot, axis = 'x'))
```

## Figure 4.20 The ROC curves for each class of the MNIST 10-class classifier

```{r figure4.20, cache=TRUE, dependson="figure4.19", fig.height=6, fig.width=6}

mnistResultsDF <- data.frame(actual = mnistTest$label,
                             fit = mnist.kknn$fit,
                             as.data.frame(mnist.kknn$prob))

plotROCs <- function(df, digitList) {
  firstPlot <- TRUE
  legendList <- NULL
  for (digit in digitList) {
    dfDigit <- df %>%
      filter(as.character(actual) == as.character(digit) |
               as.character(fit) == as.character(digit))  %>%
      mutate(prediction = (as.character(actual) == as.character(fit)))
    
    pred <- prediction(dfDigit[,digit+3], dfDigit$prediction)
    perf <- performance(pred, "tpr", "fpr")
    auc <- performance(pred, "auc")
    legendList <- append(legendList, 
                         paste0("Digit: ",digit,", AUC: ",
                                round(auc@y.values[[1]], digits = 4)))
    if (firstPlot == TRUE) {
      plot(perf, colorize = FALSE, lty = digit+1, col = digit+1)
      firstPlot <- FALSE  
    } else {
      plot(perf, colorize = FALSE, add = TRUE, lty = digit+1, col = digit+1)
    }
  }
  legend(x=0.4, y=0.6,
         legend = legendList,
         col = 1:10,
         lty = 1:10,
         bty = "n")
}

plotROCs(mnistResultsDF, 0:9)

```

## Figure 4.21 A subset of the Auto MPG dataset

```{r figure4.21, cache=TRUE}
auto <- read.csv("data/auto-mpg.csv",
                 colClasses = c(
                      origin = "factor"))

auto$origin <- revalue(auto$origin, 
                       c("1\t"="USA", "2\t"="Europe", "3\t"="Asia"))

kable(head(auto,5))
```

## Figure 4.22 Scatter plot of the predicted MPG versus actual values from the testing set. The diagonal line shows the optimal model.

```{r figure4.22, cache=TRUE, dependson="figure4.21", fig.height=4}
dummies <- dummyVars(" ~ .", data = auto, fullRank = TRUE)
autoNumeric <- data.frame(predict(dummies, newdata = auto))

kable(tail(autoNumeric,5))

trainIndex <- createDataPartition(autoNumeric$mpg, p = .8, 
                                  list = FALSE, 
                                  times = 1)

autoTrain <- autoNumeric[ trainIndex,]
autoTest  <- autoNumeric[-trainIndex,]

ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE)

auto.glm <- train(mpg ~.,  
                 data=autoTrain, 
                 method="glm", 
                 trControl = ctrl, 
                 tuneLength = 5)

auto.glm.Pred = predict(auto.glm, newdata=autoTest)

ggplot(autoTest, aes(x=mpg, y=auto.glm.Pred)) + 
  geom_point() + 
  geom_abline(slope = 1, intercept = 0) +
  labs(x="MPG", y="Predicted MPG")
```

## Listing 4.5 The root-mean-square error

The `RMSE` function is part of the `caret` package.

```{r listing4.5, cache=TRUE, dependson="figure4.22"}
RMSE(auto.glm.Pred, autoTest$mpg)
```

## Listing 4.6 The R-squared calculation

The `R2` function is part of the `caret` package.

```{r listing4.6, cache=TRUE, dependson="figure4.22"}
R2(auto.glm.Pred, autoTest$mpg)
```

## Figure 4.24 The residual plot from predictions on the MPG dataset.

```{r figure4.24, cache=TRUE, dependson="figure4.22", fig.height=4}
autoTest$residuals <- autoTest$mpg - auto.glm.Pred

ggplot(data=autoTest, aes(x=mpg, y=residuals)) +
  geom_point() + 
  geom_abline(slope = 0, intercept = 0) +
  labs(x="MPG", y="Residuals")
```

## Listing 4.7 Grid search with kernel SVM (and collection of line graphs as analog to contour plot of Figure 4.25)

The `getModelInfo` function in the `caret` package can be used to find
the available model parameters. By setting `summaryFunction = twoClassSummary`
in `trainControl`, we request `ROC` to be used to select the optimal model using 
the largest value.

```{r listing4.7, cache=TRUE, dependson="figure4.10"}
registerDoMC(cores = 2)
svmRadialModelInfo <- getModelInfo("svmRadial")
svmRadialModelInfo$svmRadial$parameters

svmGrid <- expand.grid(sigma = c(1:10 %o% 10^(-1:0)),
                       C = 1:10)

fitControl <- trainControl(method = "repeatedcv", 
                           number = 10, 
                           savePredictions = TRUE,
                           summaryFunction=twoClassSummary, 
                           classProbs=TRUE)

svmFit <- train(Survived.yes ~ ., data = titanicTrain,
                method = "svmRadial", 
                trControl = fitControl, 
                verbose = FALSE, 
                tuneGrid = svmGrid)

trellis.par.set(caretTheme())
plot(svmFit)

svmFit$bestTune
```


```{r listing4.7b, cache=TRUE, dependson="listing4.7"}
svmGrid <- expand.grid(sigma = c(1:10 %o% 10^(-2:-1)),
                       C = seq(0, 20, by = 2))

fitControl <- trainControl(method = "repeatedcv", 
                           number = 10, 
                           savePredictions = TRUE,
                           summaryFunction=twoClassSummary, 
                           classProbs=TRUE)

svmFit <- train(Survived.yes ~ ., data = titanicTrain,
                method = "svmRadial", 
                trControl = fitControl, 
                verbose = FALSE, 
                tuneGrid = svmGrid)

trellis.par.set(caretTheme())
plot(svmFit)

svmFit$bestTune

```
